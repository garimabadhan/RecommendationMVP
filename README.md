# ğŸ“ MTSS Recommendation MVP

This project provides an intelligent intervention suggestion system for Multi-Tiered System of Supports (MTSS) using AI embeddings and semantic similarity. Built with Streamlit, Google Gemini, and Sentence Transformers.

## ğŸš€ Features

- PDF chunking from MTSS guides (on-the-fly during deployment)
- SentenceTransformer-based embedding of content chunks
- Embedding of student profiles from BigQuery
- Cosine similarity to find top 5 relevant MTSS documents
- Generative AI (Gemini) to suggest classroom-friendly interventions

## ğŸ› ï¸ Tech Stack

- **Python 3.10**
- [Streamlit](https://streamlit.io/) â€“ UI
- [Google Generative AI](https://ai.google.dev/) â€“ Gemini content generation
- [Sentence Transformers](https://www.sbert.net/) â€“ Semantic similarity
- [Google BigQuery](https://cloud.google.com/bigquery) â€“ Student data store
- [Docker](https://www.docker.com/) â€“ Deployment containerization

## ğŸ§  How it works

1. MTSS PDFs are chunked by page using `pdfplumber`
2. Each chunk is embedded using `all-MiniLM-L6-v2` (from HuggingFace)
3. Student embeddings are retrieved from BigQuery and padded to 384D
4. Cosine similarity identifies top 5 similar MTSS chunks per student
5. Gemini generates 3 tailored intervention suggestions from those chunks

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ app.py                  # Main Streamlit app logic
â”œâ”€â”€ Dockerfile              # Deployment config for Cloud Run
â”œâ”€â”€ requirements.txt        # Dependencies (Streamlit, Gemini, BigQuery, etc.)
â”œâ”€â”€ models/                 # Local cache of SentenceTransformer
â”œâ”€â”€ MTSS_PDFs/              # Folder containing MTSS documents (PDF)
â”œâ”€â”€ .env                    # Contains GEMINI_API_KEY (excluded via .gitignore)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ” Setup

1. Create a `.env` file:

```env
GEMINI_API_KEY=your-actual-api-key
```

2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Run locally:

```bash
streamlit run app.py
```

## â˜ï¸ Deployment

To deploy to Google Cloud Run:

```bash
gcloud builds submit --tag gcr.io/YOUR_PROJECT_ID/mtss-ui
gcloud run deploy mtss-ui --image gcr.io/YOUR_PROJECT_ID/mtss-ui --platform managed --region us-central1 --memory 1Gi --port 8080
```

## ğŸ¤– Models Used

- **SentenceTransformer**: `all-MiniLM-L6-v2` (local)
- **Gemini**: `models/gemini-1.5-pro` (Generative content model)
- **BigQuery**: For student profile embeddings

## ğŸ“Œ Notes
- Ensure that the model all-MiniLM-L6-v2 is cached locally and included under /models/.

- MTSS PDFs must be present in MTSS_PDFs/ folder.

- You must have access to the relevant BigQuery tables (student_embeddings) in the specified project.

## ğŸ“ Example Output

- Student ID: 12345
- Profile: GPA: 2.5, Attendance: 3.0, Math: 1.5, Reading: 2.0
- ğŸ” System finds 5 most relevant MTSS chunks
- âœ¨ Gemini suggests 3 actionable interventions

## ğŸ™‹â€â™€ï¸ Author

Garima Badhan â€“ [@garimabadhan](https://github.com/garimabadhan)